{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter Image Set Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mezUFoYYsS9d",
        "colab_type": "code",
        "outputId": "234c8ff5-1e58-497b-d016-146bed381c40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "#imports\n",
        "%tensorflow_version 1.x\n",
        "import tensorflow as tf\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "# !pip install numpy==1.17.4\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "import PIL\n",
        "from matplotlib import image\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "1.15.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSv3VMt2VrqJ",
        "colab_type": "code",
        "outputId": "a6fc451d-5c46-4e51-8d58-8a3d8150d064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        }
      },
      "source": [
        "#copy folders from google.drive to colab\n",
        "# leave_out = [\".ipynb_checkpoints\", 'fonts', 'final_model', 'optimized_final_model']\n",
        "#configure path\n",
        "# for dirpath, dirnames, filenames in os.walk(\"/content/drive/My Drive/ML/Twitter_Model_Data\"):\n",
        "#   for dirname in dirnames:\n",
        "#     if(not dirname in leave_out):\n",
        "#configure path\n",
        "#       path = os.path.join(\"/content/drive/My\\ Drive/ML/Twitter_Model_Data\", dirname)\n",
        "#       dest = os.path.join(\"/content\")\n",
        "#       !cp -avr $path $dest\n",
        "#   break"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model' -> '/content/final_model'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/model.ckpt.data-00000-of-00001' -> '/content/final_model/model.ckpt.data-00000-of-00001'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/checkpoint' -> '/content/final_model/checkpoint'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/model.ckpt.index' -> '/content/final_model/model.ckpt.index'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/model.ckpt.meta' -> '/content/final_model/model.ckpt.meta'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/frozen_inference_graph.pb' -> '/content/final_model/frozen_inference_graph.pb'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/saved_model' -> '/content/final_model/saved_model'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/saved_model/variables' -> '/content/final_model/saved_model/variables'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/saved_model/saved_model.pb' -> '/content/final_model/saved_model/saved_model.pb'\n",
            "'/content/drive/My Drive/ML/Twitter_Model_Data/final_model/pipeline.config' -> '/content/final_model/pipeline.config'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4euAaneEn9pM",
        "colab_type": "code",
        "outputId": "8eb81186-564c-4368-d22c-45c56b8febc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "# # uploading files to gdrive\n",
        "\n",
        "# from google.colab import drive, files\n",
        "# import os\n",
        "# import shutil\n",
        "#configure path\n",
        "# # %cd /content/drive/My\\ Drive/ML/Twitter_Model_Data\n",
        "# %cd /content/\n",
        "\n",
        "# leave_out = [\".config\",\n",
        "#     \"models\",\n",
        "#     \"tools\",\n",
        "#     \"csvs\",\n",
        "#     \"data\",\n",
        "#     \"drive\",\n",
        "#     \"images\",\n",
        "#     \"train_dir\",\n",
        "#     \".ipynb_checkpoints\",\n",
        "#     \"model_dir\",\n",
        "#     \"sample_data\",\n",
        "#     \"final_model\",\n",
        "#     \"pre_trained\"]\n",
        "\n",
        "# for dirpath, dirnames, filenames in os.walk(\"/content\"):\n",
        "#   for dirname in dirnames:\n",
        "#     if(not dirname in leave_out):\n",
        "#       path = os.path.join(dirpath, dirname)\n",
        "#configure path\n",
        "#       dest = os.path.join(\"/content/drive/My\\ Drive/ML/Twitter_Model_Data\")\n",
        "#       if(not os.path.exists(dest)):\n",
        "#         pass\n",
        "#configure path\n",
        "#         # %cd /content/drive/My\\ Drive/ML/Twitter_Model_Data\n",
        "#         # !mkdir $dirname\n",
        "#       # %cd /content\n",
        "#       !cp -avr $path $dest\n",
        "#   break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "'/content/o_model' -> '/content/drive/My Drive/ML/Twitter_Model_Data/o_model'\n",
            "'/content/o_model/variables' -> '/content/drive/My Drive/ML/Twitter_Model_Data/o_model/variables'\n",
            "'/content/o_model/saved_model.pb' -> '/content/drive/My Drive/ML/Twitter_Model_Data/o_model/saved_model.pb'\n",
            "'/content/model_dir/twitter_model_ssd.config' -> '/content/drive/My Drive/ML/Twitter_Model_Data/model_dir/twitter_model_ssd.config'\n",
            "'/content/model_dir/twitter_model_base.config' -> '/content/drive/My Drive/ML/Twitter_Model_Data/model_dir/twitter_model_base.config'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbfP5TsGCPUk",
        "colab_type": "code",
        "outputId": "be78b095-fed3-4d4e-c608-dc6b7f5b173b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        }
      },
      "source": [
        "# install object detection api and dependencies\n",
        "# %cd /content\n",
        "# !apt-get install protobuf-compiler python-pil python-lxml python-tk\n",
        "# !pip install Cython\n",
        "# #!pip install jupyter\n",
        "# #!pip install matplotlib\n",
        "\n",
        "# !git clone https://github.com/tensorflow/models.git\n",
        "\n",
        "%cd /content/models/research\n",
        "!pip install .\n",
        "\n",
        "\n",
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "Processing /content/models/research\n",
            "Requirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (7.0.0)\n",
            "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.2.1)\n",
            "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.16)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.18.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from Matplotlib>=2.1->object-detection==0.1) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->Matplotlib>=2.1->object-detection==0.1) (1.12.0)\n",
            "Building wheels for collected packages: object-detection\n",
            "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for object-detection: filename=object_detection-0.1-cp36-none-any.whl size=1017522 sha256=a8cbaf55641bfd7f194c855357cb200da8848b031be614dd3f8048aae2e1fd3e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-oiij43im/wheels/94/49/4b/39b051683087a22ef7e80ec52152a27249d1a644ccf4e442ea\n",
            "Successfully built object-detection\n",
            "Installing collected packages: object-detection\n",
            "  Found existing installation: object-detection 0.1\n",
            "    Uninstalling object-detection-0.1:\n",
            "      Successfully uninstalled object-detection-0.1\n",
            "Successfully installed object-detection-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whG9fAm7Tw5T",
        "colab_type": "code",
        "outputId": "13eae2a7-435c-45c4-f578-7568f6bf85f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#create record files from image csvs\n",
        "%cd /content/models/research\n",
        "#configure path for the input_csv, image_dir, label_map_path, and output_path for both train and test\n",
        "!python /content/tools/generate_tf_records.py \\\n",
        "    --input_csv=/content/csvs/train_image_annotations.csv \\\n",
        "    --image_dir=/content/images/train_images \\\n",
        "    --label_map_path=/content/data/image_label_map.pbtxt \\\n",
        "    --output_path=/content/data/train_tf_records.record\n",
        "!python /content/tools/generate_tf_records.py \\\n",
        "    --input_csv=/content/csvs/test_image_annotations.csv \\\n",
        "    --image_dir=/content/images/test_images \\\n",
        "    --label_map_path=/content/data/image_label_map.pbtxt \\\n",
        "    --output_path=/content/data/test_tf_records.record"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research\n",
            "/content/data/train_tf_records.record\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created tf records file to this path: /content/data/train_tf_records.record\n",
            "/content/data/test_tf_records.record\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "Successfully created tf records file to this path: /content/data/test_tf_records.record\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LGPFIL6ZZEC",
        "colab_type": "code",
        "outputId": "2bf61d72-1986-457e-844e-8888503190ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "# %cd /content\n",
        "# !tar -xvf  'ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03.tar' -C '/content' "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckpt.meta\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/checkpoint\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/frozen_inference_graph.pb\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/saved_model/\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/saved_model/variables/\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/saved_model/saved_model.pb\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckpt.index\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/pipeline.config\n",
            "ssd_resnet50_v1_fpn_shared_box_predictor_640x640_coco14_sync_2018_07_03/model.ckpt.data-00000-of-00001\n",
            "tar: Unexpected EOF in archive\n",
            "tar: rmtlseek not stopped at a record boundary\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfVcLU4wc-21",
        "colab_type": "code",
        "outputId": "8ca7355a-3769-468f-b2a4-967edf5906a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#configure path\n",
        "%cd /content/models/research/slim\n",
        "!python setup.py build\n",
        "!python setup.py install"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/slim\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/datasets\n",
            "copying datasets/download_and_convert_mnist.py -> build/lib/datasets\n",
            "copying datasets/build_imagenet_data.py -> build/lib/datasets\n",
            "copying datasets/__init__.py -> build/lib/datasets\n",
            "copying datasets/flowers.py -> build/lib/datasets\n",
            "copying datasets/mnist.py -> build/lib/datasets\n",
            "copying datasets/visualwakewords.py -> build/lib/datasets\n",
            "copying datasets/download_and_convert_cifar10.py -> build/lib/datasets\n",
            "copying datasets/preprocess_imagenet_validation_data.py -> build/lib/datasets\n",
            "copying datasets/process_bounding_boxes.py -> build/lib/datasets\n",
            "copying datasets/imagenet.py -> build/lib/datasets\n",
            "copying datasets/dataset_utils.py -> build/lib/datasets\n",
            "copying datasets/download_and_convert_visualwakewords_lib.py -> build/lib/datasets\n",
            "copying datasets/download_and_convert_flowers.py -> build/lib/datasets\n",
            "copying datasets/cifar10.py -> build/lib/datasets\n",
            "copying datasets/download_and_convert_visualwakewords.py -> build/lib/datasets\n",
            "copying datasets/dataset_factory.py -> build/lib/datasets\n",
            "creating build/lib/nets\n",
            "copying nets/resnet_v2.py -> build/lib/nets\n",
            "copying nets/resnet_v1.py -> build/lib/nets\n",
            "copying nets/inception_v1.py -> build/lib/nets\n",
            "copying nets/cyclegan_test.py -> build/lib/nets\n",
            "copying nets/overfeat.py -> build/lib/nets\n",
            "copying nets/resnet_v2_test.py -> build/lib/nets\n",
            "copying nets/alexnet_test.py -> build/lib/nets\n",
            "copying nets/inception_v3.py -> build/lib/nets\n",
            "copying nets/post_training_quantization.py -> build/lib/nets\n",
            "copying nets/inception_v4_test.py -> build/lib/nets\n",
            "copying nets/mobilenet_v1.py -> build/lib/nets\n",
            "copying nets/mobilenet_v1_train.py -> build/lib/nets\n",
            "copying nets/i3d_test.py -> build/lib/nets\n",
            "copying nets/pix2pix_test.py -> build/lib/nets\n",
            "copying nets/cifarnet.py -> build/lib/nets\n",
            "copying nets/__init__.py -> build/lib/nets\n",
            "copying nets/vgg.py -> build/lib/nets\n",
            "copying nets/inception_utils.py -> build/lib/nets\n",
            "copying nets/lenet.py -> build/lib/nets\n",
            "copying nets/nets_factory_test.py -> build/lib/nets\n",
            "copying nets/resnet_utils.py -> build/lib/nets\n",
            "copying nets/inception_v2.py -> build/lib/nets\n",
            "copying nets/nets_factory.py -> build/lib/nets\n",
            "copying nets/s3dg.py -> build/lib/nets\n",
            "copying nets/mobilenet_v1_test.py -> build/lib/nets\n",
            "copying nets/alexnet.py -> build/lib/nets\n",
            "copying nets/resnet_v1_test.py -> build/lib/nets\n",
            "copying nets/cyclegan.py -> build/lib/nets\n",
            "copying nets/inception_resnet_v2_test.py -> build/lib/nets\n",
            "copying nets/overfeat_test.py -> build/lib/nets\n",
            "copying nets/inception_v4.py -> build/lib/nets\n",
            "copying nets/inception_v1_test.py -> build/lib/nets\n",
            "copying nets/dcgan.py -> build/lib/nets\n",
            "copying nets/vgg_test.py -> build/lib/nets\n",
            "copying nets/dcgan_test.py -> build/lib/nets\n",
            "copying nets/inception_v3_test.py -> build/lib/nets\n",
            "copying nets/i3d.py -> build/lib/nets\n",
            "copying nets/mobilenet_v1_eval.py -> build/lib/nets\n",
            "copying nets/inception_resnet_v2.py -> build/lib/nets\n",
            "copying nets/inception_v2_test.py -> build/lib/nets\n",
            "copying nets/s3dg_test.py -> build/lib/nets\n",
            "copying nets/i3d_utils.py -> build/lib/nets\n",
            "copying nets/inception.py -> build/lib/nets\n",
            "copying nets/pix2pix.py -> build/lib/nets\n",
            "creating build/lib/preprocessing\n",
            "copying preprocessing/cifarnet_preprocessing.py -> build/lib/preprocessing\n",
            "copying preprocessing/preprocessing_factory.py -> build/lib/preprocessing\n",
            "copying preprocessing/__init__.py -> build/lib/preprocessing\n",
            "copying preprocessing/inception_preprocessing.py -> build/lib/preprocessing\n",
            "copying preprocessing/vgg_preprocessing.py -> build/lib/preprocessing\n",
            "copying preprocessing/lenet_preprocessing.py -> build/lib/preprocessing\n",
            "creating build/lib/deployment\n",
            "copying deployment/__init__.py -> build/lib/deployment\n",
            "copying deployment/model_deploy_test.py -> build/lib/deployment\n",
            "copying deployment/model_deploy.py -> build/lib/deployment\n",
            "creating build/lib/nets/nasnet\n",
            "copying nets/nasnet/nasnet_utils_test.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/pnasnet_test.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/pnasnet.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/__init__.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/nasnet_test.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/nasnet.py -> build/lib/nets/nasnet\n",
            "copying nets/nasnet/nasnet_utils.py -> build/lib/nets/nasnet\n",
            "creating build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet_v2.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet_v3_test.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/__init__.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet_v2_test.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/conv_blocks.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet.py -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet_v3.py -> build/lib/nets/mobilenet\n",
            "running egg_info\n",
            "creating slim.egg-info\n",
            "writing slim.egg-info/PKG-INFO\n",
            "writing dependency_links to slim.egg-info/dependency_links.txt\n",
            "writing top-level names to slim.egg-info/top_level.txt\n",
            "writing manifest file 'slim.egg-info/SOURCES.txt'\n",
            "writing manifest file 'slim.egg-info/SOURCES.txt'\n",
            "copying datasets/download_and_convert_imagenet.sh -> build/lib/datasets\n",
            "copying datasets/download_imagenet.sh -> build/lib/datasets\n",
            "copying datasets/imagenet_2012_validation_synset_labels.txt -> build/lib/datasets\n",
            "copying datasets/imagenet_lsvrc_2015_synsets.txt -> build/lib/datasets\n",
            "copying datasets/imagenet_metadata.txt -> build/lib/datasets\n",
            "copying nets/mobilenet_v1.md -> build/lib/nets\n",
            "copying nets/mobilenet_v1.png -> build/lib/nets\n",
            "copying nets/nasnet/README.md -> build/lib/nets/nasnet\n",
            "copying nets/mobilenet/README.md -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png -> build/lib/nets/mobilenet\n",
            "copying nets/mobilenet/mobilenet_example.ipynb -> build/lib/nets/mobilenet\n",
            "creating build/lib/nets/mobilenet/g3doc\n",
            "copying nets/mobilenet/g3doc/edgetpu_latency.png -> build/lib/nets/mobilenet/g3doc\n",
            "copying nets/mobilenet/g3doc/latency_pixel1.png -> build/lib/nets/mobilenet/g3doc\n",
            "copying nets/mobilenet/g3doc/madds_top1_accuracy.png -> build/lib/nets/mobilenet/g3doc\n",
            "running install\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing slim.egg-info/PKG-INFO\n",
            "writing dependency_links to slim.egg-info/dependency_links.txt\n",
            "writing top-level names to slim.egg-info/top_level.txt\n",
            "writing manifest file 'slim.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_py\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/imagenet_lsvrc_2015_synsets.txt -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_mnist.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/build_imagenet_data.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/imagenet_2012_validation_synset_labels.txt -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/__init__.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/flowers.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/mnist.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/visualwakewords.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_cifar10.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/preprocess_imagenet_validation_data.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_imagenet.sh -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/process_bounding_boxes.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_imagenet.sh -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/imagenet_metadata.txt -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/imagenet.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/dataset_utils.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_visualwakewords_lib.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_flowers.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/cifar10.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/download_and_convert_visualwakewords.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "copying build/lib/datasets/dataset_factory.py -> build/bdist.linux-x86_64/egg/datasets\n",
            "creating build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/resnet_v2.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/resnet_v1.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v1.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/cyclegan_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/overfeat.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/resnet_v2_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "creating build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/nasnet_utils_test.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/pnasnet_test.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/pnasnet.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/__init__.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/nasnet_test.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/README.md -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/nasnet.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/nasnet/nasnet_utils.py -> build/bdist.linux-x86_64/egg/nets/nasnet\n",
            "copying build/lib/nets/alexnet_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v3.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/post_training_quantization.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1.png -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v4_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1_train.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/i3d_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/pix2pix_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/cifarnet.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/__init__.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/vgg.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_utils.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/lenet.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/nets_factory_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/resnet_utils.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v2.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/nets_factory.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/s3dg.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/alexnet.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/resnet_v1_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/cyclegan.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_resnet_v2_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/overfeat_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v4.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v1_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/dcgan.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/vgg_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/dcgan_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "creating build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mobilenet_example.ipynb -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "creating build/bdist.linux-x86_64/egg/nets/mobilenet/g3doc\n",
            "copying build/lib/nets/mobilenet/g3doc/madds_top1_accuracy.png -> build/bdist.linux-x86_64/egg/nets/mobilenet/g3doc\n",
            "copying build/lib/nets/mobilenet/g3doc/latency_pixel1.png -> build/bdist.linux-x86_64/egg/nets/mobilenet/g3doc\n",
            "copying build/lib/nets/mobilenet/g3doc/edgetpu_latency.png -> build/bdist.linux-x86_64/egg/nets/mobilenet/g3doc\n",
            "copying build/lib/nets/mobilenet/mobilenet_v2.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mobilenet_v3_test.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mnet_v1_vs_v2_pixel1_latency.png -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/__init__.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mobilenet_v2_test.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/conv_blocks.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/README.md -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mobilenet.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/mobilenet/mobilenet_v3.py -> build/bdist.linux-x86_64/egg/nets/mobilenet\n",
            "copying build/lib/nets/inception_v3_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/i3d.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1_eval.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/mobilenet_v1.md -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_resnet_v2.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception_v2_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/s3dg_test.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/i3d_utils.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/inception.py -> build/bdist.linux-x86_64/egg/nets\n",
            "copying build/lib/nets/pix2pix.py -> build/bdist.linux-x86_64/egg/nets\n",
            "creating build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/cifarnet_preprocessing.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/preprocessing_factory.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/__init__.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/inception_preprocessing.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/vgg_preprocessing.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "copying build/lib/preprocessing/lenet_preprocessing.py -> build/bdist.linux-x86_64/egg/preprocessing\n",
            "creating build/bdist.linux-x86_64/egg/deployment\n",
            "copying build/lib/deployment/__init__.py -> build/bdist.linux-x86_64/egg/deployment\n",
            "copying build/lib/deployment/model_deploy_test.py -> build/bdist.linux-x86_64/egg/deployment\n",
            "copying build/lib/deployment/model_deploy.py -> build/bdist.linux-x86_64/egg/deployment\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/download_and_convert_mnist.py to download_and_convert_mnist.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/build_imagenet_data.py to build_imagenet_data.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/flowers.py to flowers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/mnist.py to mnist.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/visualwakewords.py to visualwakewords.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/download_and_convert_cifar10.py to download_and_convert_cifar10.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/preprocess_imagenet_validation_data.py to preprocess_imagenet_validation_data.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/process_bounding_boxes.py to process_bounding_boxes.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/imagenet.py to imagenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/dataset_utils.py to dataset_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/download_and_convert_visualwakewords_lib.py to download_and_convert_visualwakewords_lib.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/download_and_convert_flowers.py to download_and_convert_flowers.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/cifar10.py to cifar10.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/download_and_convert_visualwakewords.py to download_and_convert_visualwakewords.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/datasets/dataset_factory.py to dataset_factory.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/resnet_v2.py to resnet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/resnet_v1.py to resnet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v1.py to inception_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/cyclegan_test.py to cyclegan_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/overfeat.py to overfeat.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/resnet_v2_test.py to resnet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/nasnet_utils_test.py to nasnet_utils_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/pnasnet_test.py to pnasnet_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/pnasnet.py to pnasnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/nasnet_test.py to nasnet_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/nasnet.py to nasnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nasnet/nasnet_utils.py to nasnet_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/alexnet_test.py to alexnet_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v3.py to inception_v3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/post_training_quantization.py to post_training_quantization.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v4_test.py to inception_v4_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet_v1.py to mobilenet_v1.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet_v1_train.py to mobilenet_v1_train.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/i3d_test.py to i3d_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/pix2pix_test.py to pix2pix_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/cifarnet.py to cifarnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/vgg.py to vgg.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_utils.py to inception_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/lenet.py to lenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nets_factory_test.py to nets_factory_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/resnet_utils.py to resnet_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v2.py to inception_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/nets_factory.py to nets_factory.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/s3dg.py to s3dg.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet_v1_test.py to mobilenet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/alexnet.py to alexnet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/resnet_v1_test.py to resnet_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/cyclegan.py to cyclegan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_resnet_v2_test.py to inception_resnet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/overfeat_test.py to overfeat_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v4.py to inception_v4.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v1_test.py to inception_v1_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/dcgan.py to dcgan.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/vgg_test.py to vgg_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/dcgan_test.py to dcgan_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/mobilenet_v2.py to mobilenet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/mobilenet_v3_test.py to mobilenet_v3_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/mobilenet_v2_test.py to mobilenet_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/conv_blocks.py to conv_blocks.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/mobilenet.py to mobilenet.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet/mobilenet_v3.py to mobilenet_v3.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v3_test.py to inception_v3_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/i3d.py to i3d.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/mobilenet_v1_eval.py to mobilenet_v1_eval.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_resnet_v2.py to inception_resnet_v2.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception_v2_test.py to inception_v2_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/s3dg_test.py to s3dg_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/i3d_utils.py to i3d_utils.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/inception.py to inception.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nets/pix2pix.py to pix2pix.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/cifarnet_preprocessing.py to cifarnet_preprocessing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/preprocessing_factory.py to preprocessing_factory.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/inception_preprocessing.py to inception_preprocessing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/vgg_preprocessing.py to vgg_preprocessing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/preprocessing/lenet_preprocessing.py to lenet_preprocessing.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/deployment/__init__.py to __init__.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/deployment/model_deploy_test.py to model_deploy_test.cpython-36.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/deployment/model_deploy.py to model_deploy.cpython-36.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying slim.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying slim.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying slim.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying slim.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "creating dist\n",
            "creating 'dist/slim-0.1-py3.6.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing slim-0.1-py3.6.egg\n",
            "Copying slim-0.1-py3.6.egg to /usr/local/lib/python3.6/dist-packages\n",
            "Adding slim 0.1 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.6/dist-packages/slim-0.1-py3.6.egg\n",
            "Processing dependencies for slim==0.1\n",
            "Finished processing dependencies for slim==0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jmk7Fd6_Q_2x",
        "colab_type": "code",
        "outputId": "8838f236-007d-43c4-d56e-db4a333c943b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "%cd /content\n",
        "#train model\n",
        "!mkdir train_dir\n",
        "#configure path for config path and model dir\n",
        "PIPELINE_CONFIG_PATH=\"/content/model_dir/twitter_model_ssd.config\"\n",
        "MODEL_DIR=\"/content/train_dir\"\n",
        "NUM_TRAIN_STEPS=50000\n",
        "SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n",
        "#configure path to wherever the model_main file is in the object detection api\n",
        "!python /content/models/research/object_detection/model_main.py \\\n",
        "    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n",
        "    --model_dir={MODEL_DIR} \\\n",
        "    --alsologtostderr\n",
        "    # --num_train_steps={NUM_TRAIN_STEPS} \\\n",
        "    # --sample_1_of_n_eval_examples={SAMPLE_1_OF_N_EVAL_EXAMPLES} \\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-3-e270b6b6134e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    $cd /content\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dR6gDvlW5w4",
        "colab_type": "code",
        "outputId": "ae44a632-6387-4af6-c11e-630f181bcb5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "$cd /content\n",
        "#create frozen graph\n",
        "!mkdir final_model\n",
        "%cd /content/models/research/object_detection\n",
        "!python export_inference_graph.py \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path /content/model_dir/twitter_model_ssd.config \\\n",
        "    --trained_checkpoint_prefix /content/train_dir/model.ckpt-25000 \\\n",
        "    --output_directory /content/final_model"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0420 07:04:18.306520 139847481481088 module_wrapper.py:139] From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0420 07:04:18.314574 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0420 07:04:18.314955 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "W0420 07:04:18.357253 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0420 07:04:18.391981 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0420 07:04:18.396487 139847481481088 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0420 07:04:20.759640 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0420 07:04:21.583587 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0420 07:04:22.958126 139847481481088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "W0420 07:04:23.350838 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "W0420 07:04:23.351176 139847481481088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please switch to tf.train.get_or_create_global_step\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0420 07:04:23.355909 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "W0420 07:04:23.356162 139847481481088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n",
            "Instructions for updating:\n",
            "Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "W0420 07:04:23.358163 139847481481088 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
            "175 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              0\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   name\n",
            "-account_type_regexes       _trainable_variables\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     params\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "param: Number of parameters (in the Variable).\n",
            "\n",
            "Profile:\n",
            "node name | # parameters\n",
            "_TFProfRoot (--/31.53m params)\n",
            "  FeatureExtractor (--/26.73m params)\n",
            "    FeatureExtractor/resnet_v1_50 (--/26.73m params)\n",
            "      FeatureExtractor/resnet_v1_50/block1 (--/212.99k params)\n",
            "        FeatureExtractor/resnet_v1_50/block1/unit_1 (--/73.73k params)\n",
            "          FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1 (--/73.73k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1 (--/4.10k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv1/weights (1x1x64x64, 4.10k/4.10k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_1/bottleneck_v1/shortcut/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FeatureExtractor/resnet_v1_50/block1/unit_2 (--/69.63k params)\n",
            "          FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1 (--/69.63k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_2/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "        FeatureExtractor/resnet_v1_50/block1/unit_3 (--/69.63k params)\n",
            "          FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1 (--/69.63k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1 (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv1/weights (1x1x256x64, 16.38k/16.38k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2 (--/36.86k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv2/weights (3x3x64x64, 36.86k/36.86k params)\n",
            "            FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3 (--/16.38k params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block1/unit_3/bottleneck_v1/conv3/weights (1x1x64x256, 16.38k/16.38k params)\n",
            "      FeatureExtractor/resnet_v1_50/block2 (--/1.21m params)\n",
            "        FeatureExtractor/resnet_v1_50/block2/unit_1 (--/376.83k params)\n",
            "          FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1 (--/376.83k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1 (--/32.77k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv1/weights (1x1x256x128, 32.77k/32.77k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut (--/131.07k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_1/bottleneck_v1/shortcut/weights (1x1x256x512, 131.07k/131.07k params)\n",
            "        FeatureExtractor/resnet_v1_50/block2/unit_2 (--/278.53k params)\n",
            "          FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1 (--/278.53k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_2/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FeatureExtractor/resnet_v1_50/block2/unit_3 (--/278.53k params)\n",
            "          FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1 (--/278.53k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_3/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "        FeatureExtractor/resnet_v1_50/block2/unit_4 (--/278.53k params)\n",
            "          FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1 (--/278.53k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv1/weights (1x1x512x128, 65.54k/65.54k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2 (--/147.46k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv2/weights (3x3x128x128, 147.46k/147.46k params)\n",
            "            FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3 (--/65.54k params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block2/unit_4/bottleneck_v1/conv3/weights (1x1x128x512, 65.54k/65.54k params)\n",
            "      FeatureExtractor/resnet_v1_50/block3 (--/7.08m params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_1 (--/1.51m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1 (--/1.51m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1 (--/131.07k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv1/weights (1x1x512x256, 131.07k/131.07k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut (--/524.29k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_1/bottleneck_v1/shortcut/weights (1x1x512x1024, 524.29k/524.29k params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_2 (--/1.11m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1 (--/1.11m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_2/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_3 (--/1.11m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1 (--/1.11m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_3/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_4 (--/1.11m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1 (--/1.11m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_4/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_5 (--/1.11m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1 (--/1.11m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_5/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "        FeatureExtractor/resnet_v1_50/block3/unit_6 (--/1.11m params)\n",
            "          FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1 (--/1.11m params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv1/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2 (--/589.82k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "            FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3 (--/262.14k params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block3/unit_6/bottleneck_v1/conv3/weights (1x1x256x1024, 262.14k/262.14k params)\n",
            "      FeatureExtractor/resnet_v1_50/block4 (--/14.94m params)\n",
            "        FeatureExtractor/resnet_v1_50/block4/unit_1 (--/6.03m params)\n",
            "          FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1 (--/6.03m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1 (--/524.29k params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv1/weights (1x1x1024x512, 524.29k/524.29k params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut (--/2.10m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_1/bottleneck_v1/shortcut/weights (1x1x1024x2048, 2.10m/2.10m params)\n",
            "        FeatureExtractor/resnet_v1_50/block4/unit_2 (--/4.46m params)\n",
            "          FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1 (--/4.46m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_2/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "        FeatureExtractor/resnet_v1_50/block4/unit_3 (--/4.46m params)\n",
            "          FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1 (--/4.46m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1 (--/1.05m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv1/weights (1x1x2048x512, 1.05m/1.05m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2 (--/2.36m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv2/weights (3x3x512x512, 2.36m/2.36m params)\n",
            "            FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3 (--/1.05m params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/BatchNorm (--/0 params)\n",
            "              FeatureExtractor/resnet_v1_50/block4/unit_3/bottleneck_v1/conv3/weights (1x1x512x2048, 1.05m/1.05m params)\n",
            "      FeatureExtractor/resnet_v1_50/conv1 (--/9.41k params)\n",
            "        FeatureExtractor/resnet_v1_50/conv1/BatchNorm (--/0 params)\n",
            "        FeatureExtractor/resnet_v1_50/conv1/weights (7x7x3x64, 9.41k/9.41k params)\n",
            "      FeatureExtractor/resnet_v1_50/fpn (--/3.28m params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5 (--/589.82k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/bottom_up_block5/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6 (--/589.82k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/bottom_up_block6/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/projection_1 (--/131.33k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_1/biases (256, 256/256 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_1/weights (1x1x512x256, 131.07k/131.07k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/projection_2 (--/262.40k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_2/biases (256, 256/256 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_2/weights (1x1x1024x256, 262.14k/262.14k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/projection_3 (--/524.54k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_3/biases (256, 256/256 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/projection_3/weights (1x1x2048x256, 524.29k/524.29k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/smoothing_1 (--/589.82k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/smoothing_1/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/smoothing_1/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "        FeatureExtractor/resnet_v1_50/fpn/smoothing_2 (--/589.82k params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/smoothing_2/BatchNorm (--/0 params)\n",
            "          FeatureExtractor/resnet_v1_50/fpn/smoothing_2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "  WeightSharedConvolutionalBoxPredictor (--/4.80m params)\n",
            "    WeightSharedConvolutionalBoxPredictor/BoxPredictionTower (--/2.36m params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_0/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_1/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/BoxPredictionTower/conv2d_3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "    WeightSharedConvolutionalBoxPredictor/BoxPredictor (--/55.32k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictor/biases (24, 24/24 params)\n",
            "      WeightSharedConvolutionalBoxPredictor/BoxPredictor/weights (3x3x256x24, 55.30k/55.30k params)\n",
            "    WeightSharedConvolutionalBoxPredictor/ClassPredictionTower (--/2.36m params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_0/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_1/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_2/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3 (--/589.82k params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/BatchNorm (--/0 params)\n",
            "        WeightSharedConvolutionalBoxPredictor/ClassPredictionTower/conv2d_3/weights (3x3x256x256, 589.82k/589.82k params)\n",
            "    WeightSharedConvolutionalBoxPredictor/ClassPredictor (--/27.66k params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictor/biases (12, 12/12 params)\n",
            "      WeightSharedConvolutionalBoxPredictor/ClassPredictor/weights (3x3x256x12, 27.65k/27.65k params)\n",
            "\n",
            "======================End of Report==========================\n",
            "175 ops no flops stats due to incomplete shapes.\n",
            "Parsing Inputs...\n",
            "Incomplete shape.\n",
            "\n",
            "=========================Options=============================\n",
            "-max_depth                  10000\n",
            "-min_bytes                  0\n",
            "-min_peak_bytes             0\n",
            "-min_residual_bytes         0\n",
            "-min_output_bytes           0\n",
            "-min_micros                 0\n",
            "-min_accelerator_micros     0\n",
            "-min_cpu_micros             0\n",
            "-min_params                 0\n",
            "-min_float_ops              1\n",
            "-min_occurrence             0\n",
            "-step                       -1\n",
            "-order_by                   float_ops\n",
            "-account_type_regexes       .*\n",
            "-start_name_regexes         .*\n",
            "-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n",
            "-show_name_regexes          .*\n",
            "-hide_name_regexes          \n",
            "-account_displayed_op_only  true\n",
            "-select                     float_ops\n",
            "-output                     stdout:\n",
            "\n",
            "==================Model Analysis Report======================\n",
            "Incomplete shape.\n",
            "\n",
            "Doc:\n",
            "scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n",
            "flops: Number of float operations. Note: Please read the implementation for the math behind it.\n",
            "\n",
            "Profile:\n",
            "node name | # float_ops\n",
            "_TFProfRoot (--/511.99k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_5 (76.80k/76.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_6 (76.80k/76.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/sub (76.80k/76.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/Scale/mul (38.40k/38.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/Scale/mul_1 (38.40k/38.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/Scale/mul_3 (38.40k/38.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/Scale/mul_2 (38.40k/38.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/sub (19.20k/19.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_6 (19.20k/19.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_5 (19.20k/19.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/Scale/mul_1 (9.60k/9.60k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/Scale/mul_2 (9.60k/9.60k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/Scale/mul (9.60k/9.60k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/Scale/mul_3 (9.60k/9.60k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/sub (4.80k/4.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_6 (4.80k/4.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_5 (4.80k/4.80k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/Scale/mul_3 (2.40k/2.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/Scale/mul_2 (2.40k/2.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/Scale/mul_1 (2.40k/2.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/Scale/mul (2.40k/2.40k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_5 (1.20k/1.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_6 (1.20k/1.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/sub (1.20k/1.20k flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/Scale/mul (600/600 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/Scale/mul_3 (600/600 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/Scale/mul_2 (600/600 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/Scale/mul_1 (600/600 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/sub (300/300 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_6 (300/300 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_5 (300/300 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/Scale/mul (150/150 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/Scale/mul_1 (150/150 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/Scale/mul_2 (150/150 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/Scale/mul_3 (150/150 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_4 (80/80 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_3 (80/80 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_4 (40/40 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_3 (40/40 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_4 (20/20 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_3 (20/20 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_3 (10/10 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_4 (10/10 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/truediv (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/truediv (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_1 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/truediv (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_2 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/mul_2 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/truediv (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul_1 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/mul (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_1 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/mul_2 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/truediv (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_2 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_1 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_2 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/mul_1 (6/6 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_3 (5/5 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/mul_4 (5/5 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n",
            "  Preprocessor/map/while/Less_1 (1/1 flops)\n",
            "  Preprocessor/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_4/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/truediv (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates/truediv_1 (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_3/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/truediv (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_1/truediv_1 (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_2/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/truediv (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_2/truediv_1 (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator_1/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/truediv (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_3/truediv_1 (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/GridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/truediv (1/1 flops)\n",
            "  MultiscaleGridAnchorGenerator/ToNormalizedCoordinates_4/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n",
            "  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n",
            "\n",
            "======================End of Report==========================\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0420 07:04:24.970961 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0420 07:04:26.482589 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-20 07:04:26.490954: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-20 07:04:26.509505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.510373: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-20 07:04:26.510732: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 07:04:26.526816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 07:04:26.545843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 07:04:26.561266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 07:04:26.576645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 07:04:26.592304: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 07:04:26.617811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 07:04:26.617987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.618993: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.619875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-20 07:04:26.636510: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n",
            "2020-04-20 07:04:26.636862: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22a5100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-20 07:04:26.636900: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2020-04-20 07:04:26.736467: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.737536: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22a4d80 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-20 07:04:26.737588: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
            "2020-04-20 07:04:26.737928: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.738840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-20 07:04:26.738927: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 07:04:26.738976: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 07:04:26.739020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 07:04:26.739066: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 07:04:26.739129: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 07:04:26.739169: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 07:04:26.739209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 07:04:26.739377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.740335: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.741187: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-20 07:04:26.741255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 07:04:26.742875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-20 07:04:26.742908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-20 07:04:26.742924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-20 07:04:26.743101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.744221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:26.745105: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2020-04-20 07:04:26.745158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/train_dir/model.ckpt-25000\n",
            "I0420 07:04:26.747332 139847481481088 saver.py:1284] Restoring parameters from /content/train_dir/model.ckpt-25000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0420 07:04:29.410751 139847481481088 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "2020-04-20 07:04:30.579713: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:30.580627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-20 07:04:30.580820: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 07:04:30.580880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 07:04:30.580938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 07:04:30.580990: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 07:04:30.581035: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 07:04:30.581087: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 07:04:30.581159: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 07:04:30.581329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:30.582343: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:30.583328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-20 07:04:30.583448: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-20 07:04:30.583474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-20 07:04:30.583494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-20 07:04:30.583685: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:30.584723: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:30.585633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "INFO:tensorflow:Restoring parameters from /content/train_dir/model.ckpt-25000\n",
            "I0420 07:04:30.587141 139847481481088 saver.py:1284] Restoring parameters from /content/train_dir/model.ckpt-25000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0420 07:04:31.586421 139847481481088 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0420 07:04:31.586840 139847481481088 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 463 variables.\n",
            "I0420 07:04:32.195307 139847481481088 graph_util_impl.py:334] Froze 463 variables.\n",
            "INFO:tensorflow:Converted 463 variables to const ops.\n",
            "I0420 07:04:32.564363 139847481481088 graph_util_impl.py:394] Converted 463 variables to const ops.\n",
            "2020-04-20 07:04:33.009154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:33.010315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n",
            "pciBusID: 0000:00:04.0\n",
            "2020-04-20 07:04:33.010448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-04-20 07:04:33.010507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2020-04-20 07:04:33.010561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2020-04-20 07:04:33.010613: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2020-04-20 07:04:33.010695: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2020-04-20 07:04:33.010757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2020-04-20 07:04:33.010816: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2020-04-20 07:04:33.010975: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:33.012307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:33.013366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2020-04-20 07:04:33.013445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2020-04-20 07:04:33.013477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2020-04-20 07:04:33.013519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2020-04-20 07:04:33.013822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:33.014990: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2020-04-20 07:04:33.016033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "W0420 07:04:33.902882 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "W0420 07:04:33.903454 139847481481088 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "W0420 07:04:33.904128 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "W0420 07:04:33.904357 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "W0420 07:04:33.904716 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "W0420 07:04:33.904938 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n",
            "\n",
            "INFO:tensorflow:No assets to save.\n",
            "I0420 07:04:33.905281 139847481481088 builder_impl.py:640] No assets to save.\n",
            "INFO:tensorflow:No assets to write.\n",
            "I0420 07:04:33.905441 139847481481088 builder_impl.py:460] No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/final_model/saved_model/saved_model.pb\n",
            "I0420 07:04:34.719062 139847481481088 builder_impl.py:425] SavedModel written to: /content/final_model/saved_model/saved_model.pb\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0420 07:04:34.787026 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:189: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0420 07:04:34.787366 139847481481088 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/utils/config_util.py:189: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Writing pipeline config file to /content/final_model/pipeline.config\n",
            "I0420 07:04:34.787531 139847481481088 config_util.py:190] Writing pipeline config file to /content/final_model/pipeline.config\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gk2p5Ytb7GDT",
        "colab_type": "code",
        "outputId": "ccac4c7f-c559-45dc-e562-7c1c34ed9a1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#export tflite graph\n",
        "#configure path for the path toe export_tflite_ssd_graph\n",
        "%cd /content/models/research/object_detection\n",
        "!python export_tflite_ssd_graph.py \\\n",
        "--input_type image_tensor \\\n",
        "--pipeline_config_path /content/model_dir/twitter_model_ssd.config \\\n",
        "--trained_checkpoint_prefix /content/final_model/model.ckpt \\\n",
        "--output_directory /content/new_final_model -add_postprocessing_op True --max_detections 10"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/models/research/object_detection\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From export_tflite_ssd_graph.py:143: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n",
            "\n",
            "WARNING:tensorflow:From export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "W0422 08:25:07.265715 140162422421376 module_wrapper.py:139] From export_tflite_ssd_graph.py:133: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "W0422 08:25:07.269388 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:193: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0422 08:25:07.269731 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:237: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "W0422 08:25:07.273482 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "W0422 08:25:07.277003 140162422421376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.__call__` method instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "W0422 08:25:09.104104 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "W0422 08:25:09.674714 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/predictors/convolutional_box_predictor.py:380: The name tf.AUTO_REUSE is deprecated. Please use tf.compat.v1.AUTO_REUSE instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "W0422 08:25:10.642884 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:52: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "2020-04-22 08:25:10.644092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2020-04-22 08:25:10.645786: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "2020-04-22 08:25:10.645821: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (b27a6efc4ece): /proc/driver/nvidia/version does not exist\n",
            "2020-04-22 08:25:10.651147: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\n",
            "2020-04-22 08:25:10.651346: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x177cf40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2020-04-22 08:25:10.651406: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "W0422 08:25:10.832070 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:267: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:59: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0422 08:25:10.835748 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:59: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:64: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "W0422 08:25:10.841754 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:64: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:75: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "W0422 08:25:10.851535 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/exporter.py:75: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n",
            "INFO:tensorflow:Found and fixed 2 matches\n",
            "I0422 08:25:10.851700 140162422421376 exporter.py:75] Found and fixed 2 matches\n",
            "INFO:tensorflow:Found and fixed 0 matches\n",
            "I0422 08:25:10.863430 140162422421376 exporter.py:75] Found and fixed 0 matches\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "W0422 08:25:10.863628 140162422421376 module_wrapper.py:139] From /usr/local/lib/python3.6/dist-packages/object_detection/export_tflite_ssd_graph_lib.py:292: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
            "\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "W0422 08:25:11.272641 140162422421376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n",
            "INFO:tensorflow:Restoring parameters from /content/final_model/model.ckpt\n",
            "I0422 08:25:11.812513 140162422421376 saver.py:1284] Restoring parameters from /content/final_model/model.ckpt\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0422 08:25:12.703148 140162422421376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "W0422 08:25:12.703458 140162422421376 deprecation.py:323] From /tensorflow-1.15.2/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
            "INFO:tensorflow:Froze 463 variables.\n",
            "I0422 08:25:13.164302 140162422421376 graph_util_impl.py:334] Froze 463 variables.\n",
            "INFO:tensorflow:Converted 463 variables to const ops.\n",
            "I0422 08:25:13.385916 140162422421376 graph_util_impl.py:394] Converted 463 variables to const ops.\n",
            "2020-04-22 08:25:13.759621: I tensorflow/tools/graph_transforms/transform_graph.cc:317] Applying strip_unused_nodes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eH3CUyb1ZMp_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.tools.graph_transforms import TransformGraph\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python import ops\n",
        "\n",
        "#describe graph nodes\n",
        "def describe_graph(graph_def, show_nodes=False):\n",
        "  print(\"Input Feature Nodes: {}\".format(\n",
        "      [node.name for node in graph_def.node if node.op == \"Placeholder\"]\n",
        "  ))\n",
        "  print('')\n",
        "  print('Unused nodes: {}'.format(\n",
        "      [node.name for node in graph_def.nodes if 'unused' in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print('Output Nodes: {}'.format(\n",
        "      [node.name for node in graph_def.nodes if \"predictions\" in node.name or \"softmax\" in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Quantization Variables: {}\".format(\n",
        "      [node.name for node in graph_def.nodes if \"quant\" in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Variables: {}\".format(\n",
        "      len([node.name for node in graph_def.nodes if node.op == \"Variable\"])\n",
        "  ))\n",
        "  print('')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA_F_sswiwd_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.tools.graph_transforms import TransformGraph\n",
        "from tensorflow.python.saved_model import tag_constants\n",
        "from tensorflow.python import ops\n",
        "\n",
        "#extra functions\n",
        "\n",
        "\n",
        "def describe_graph(graph_def, show_nodes=False):\n",
        "  print(\"Input Feature Nodes: {}\".format(\n",
        "      [node.name for node in graph_def.node if node.op==\"Placeholder\"]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Unused Nodes: {}\".format(\n",
        "      [node.name for node in graph_def.node if 'unused' in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Output nodes: {}\".format(\n",
        "      [node.name for node in graph_def.node if 'predictions' in node.name or 'softmax' in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Quantization Variables: {}\".format(\n",
        "      [node.name for node in graph_def.node if \"quant\" in node.name]\n",
        "  ))\n",
        "  print('')\n",
        "  print(\"Constants: {}\".format(\n",
        "      len([node for node in graph_def.node if node.op==\"Const\"])\n",
        "  ))\n",
        "  print(\"Variables: {}\".format(\n",
        "      len([node.name for node in graph_def.node if \"Variable\" in node.op])\n",
        "  ))\n",
        "  print('')\n",
        "  print('Identity Count: {}'.format(\n",
        "      len([node for node in graph_def.node if node.op == \"Identity\"])\n",
        "  ))\n",
        "  print('', 'Total Nodes: {}'.format(len(graph_def.node)), '')\n",
        "\n",
        "  if(show_nodes == True):\n",
        "    for node in graph_def.node:\n",
        "      print('Op: - {}, Name: {}'.format(node.op, node.name))\n",
        "\n",
        "\n",
        "\n",
        "def get_size(model_dir, model_file='saved_model.pb'):\n",
        "  model_file_path = os.path.join(model_dir, model_file)\n",
        "  print(model_file_path, '')\n",
        "  pb_size = os.path.getsize(model_file_path)\n",
        "  variables_size = 0\n",
        "  if os.path.exists(\n",
        "      os.path.join(model_dir,'variables/variables.data-00000-of-00001')):\n",
        "    variables_size = os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.data-00000-of-00001'))\n",
        "    variables_size += os.path.getsize(os.path.join(\n",
        "        model_dir,'variables/variables.index'))\n",
        "  print('Model size: {} KB'.format(round(pb_size/(1024.0),3)))\n",
        "  print('Variables size: {} KB'.format(round( variables_size/(1024.0),3)))\n",
        "  print('Total Size: {} KB'.format(round((pb_size + variables_size)/(1024.0),3)))\n",
        "\n",
        "def get_graph_def_from_saved_model(saved_model_dir): \n",
        "  with tf.Session() as session:\n",
        "    meta_graph_def = tf.saved_model.loader.load(\n",
        "    session,\n",
        "    tags=[tag_constants.SERVING],\n",
        "    export_dir=saved_model_dir\n",
        "  ) \n",
        "  return meta_graph_def.graph_def\n",
        "\n",
        "def get_graph_def_from_file(graph_filepath):\n",
        "  #graph must be a frozen inference graph not saved_mode.pb, their formats are different\n",
        "  with ops.Graph().as_default():\n",
        "    with tf.gfile.GFile(graph_filepath, 'rb') as f:\n",
        "      graph_def = tf.GraphDef()\n",
        "      #read frozen inference graph and parse it\n",
        "      graph_def.ParseFromString(f.read())\n",
        "      return graph_def\n",
        "\n",
        "def get_output_nodes(graph_def):\n",
        "  output_nodes = []\n",
        "  print(\"listing output nodes...\")\n",
        "  for node in graph_def.node:\n",
        "    if node.op == \"Identity\" and \"detection\" in node.name:\n",
        "      print(\"OP: {}, NAME: {}\".format(node.op, node.name))\n",
        "      output_nodes.append(node)\n",
        "  return output_nodes\n",
        "\n",
        "def optimize_graph(saved_model_dir, graph_filepath, transforms,output_dir):\n",
        "  #get graph definition\n",
        "  if(graph_filepath == None):\n",
        "    graph_def = get_graph_def_from_file(graph_filepath)\n",
        "  else:\n",
        "    graph_def = get_graph_def_from_saved_model(saved_model_dir)\n",
        "  #set inputs and outputs\n",
        "  input_names = []\n",
        "  #get name value for each node\n",
        "  output_names = [node.name for node in get_output_nodes()]\n",
        "  optimized_graph_def = TransformGraph(\n",
        "      graph_def,\n",
        "      input_names,\n",
        "      output_names,\n",
        "      transforms)\n",
        "  tf.train.write_graph(optimized_graph_def,\n",
        "                      logdir=output_dir,\n",
        "                      as_text=False,\n",
        "                      name='optimized_model.pb')\n",
        "  print('Graph optimized!')\n",
        "\n",
        "def convert_graph_def_to_saved_model(export_dir, graph_filepath):\n",
        "  #delete any existing files\n",
        "  if tf.gfile.Exists(export_dir):\n",
        "    tf.gfile.DeleteRecursively(export_dir)\n",
        "  graph_def = get_graph_def_from_file(graph_filepath)\n",
        "  output_nodes = get_output_nodes(graph_def)\n",
        "  with tf.Session(graph=tf.Graph()) as session:\n",
        "    tf.import_graph_def(graph_def, name='')\n",
        "    tf.saved_model.simple_save(\n",
        "        session,\n",
        "        export_dir,\n",
        "        inputs={\n",
        "            node.name: session.graph.get_tensor_by_name(\n",
        "                '{}:0'.format(node.name))\n",
        "            for node in graph_def.node if node.op=='Placeholder'},\n",
        "        outputs={node.name: session.graph.get_tensor_by_name(\"{}:0\".format(node.name)) for node in output_nodes}\n",
        "    )\n",
        "    print('Optimized graph converted to SavedModel!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wVWtoZejblm",
        "colab_type": "code",
        "outputId": "6605ba50-47d0-43c3-ea32-368d58aa0b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        }
      },
      "source": [
        "#configure path\n",
        "model_dir = \"/content/final_model/saved_model\"\n",
        "graph_def = get_graph_def_from_saved_model(model_dir)\n",
        "describe_graph(graph_def)\n",
        "get_size(model_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
            "Input Feature Nodes: ['image_tensor']\n",
            "\n",
            "Unused Nodes: []\n",
            "\n",
            "Output nodes: []\n",
            "\n",
            "Quantization Variables: []\n",
            "\n",
            "Constants: 1476\n",
            "Variables: 0\n",
            "\n",
            "Identity Count: 543\n",
            " Total Nodes: 3408 \n",
            "/content/final_model/saved_model/saved_model.pb \n",
            "Model size: 124686.441 KB\n",
            "Variables size: 0.0 KB\n",
            "Total Size: 124686.441 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "My7vsCzxk5_J",
        "colab_type": "code",
        "outputId": "f0b72289-f991-4d8f-8c5c-adff74c92227",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "#configure path\n",
        "output_dir = '/content'\n",
        "transforms = [\n",
        " \"remove_nodes(op=Identity)\", \n",
        " \"merge_duplicate_nodes\",\n",
        " \"strip_unused_nodes\",\n",
        " \"fold_constants(ignore_errors=true)\",\n",
        " \"fold_batch_norms\",\n",
        " \"quantize_nodes\",\n",
        " \"quantize_weights\"\n",
        "]\n",
        "optimize_graph(model_dir, None, transforms, output_dir)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "INFO:tensorflow:The specified SavedModel has no variables; no checkpoints were restored.\n",
            "Graph optimized!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPBIhizMytfy",
        "colab_type": "code",
        "outputId": "6842fb61-1eea-4b47-bda6-83e9aa50e97b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        }
      },
      "source": [
        "#configure path\n",
        "convert_graph_def_to_saved_model(\"o_model\", \"/content/optimized_model.pb\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "listing output nodes...\n",
            "OP: Identity, NAME: detection_scores\n",
            "OP: Identity, NAME: detection_boxes\n",
            "OP: Identity, NAME: detection_classes\n",
            "OP: Identity, NAME: detection_multiclass_scores\n",
            "OP: Identity, NAME: raw_detection_scores\n",
            "OP: Identity, NAME: num_detections\n",
            "OP: Identity, NAME: raw_detection_boxes\n",
            "WARNING:tensorflow:From <ipython-input-87-ae21712beb42>:121: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: o_model/saved_model.pb\n",
            "Optimized graph converted to SavedModel!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}